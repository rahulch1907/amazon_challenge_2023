{"cells": [{"metadata": {}, "cell_type": "code", "source": "!pip install nltk", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Collecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: click in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from nltk) (8.0.4)\nRequirement already satisfied: joblib in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from nltk) (1.1.1)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from nltk) (4.64.0)\nCollecting regex>=2021.8.3\n  Downloading regex-2023.3.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m769.6/769.6 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: regex, nltk\nSuccessfully installed nltk-3.8.1 regex-2023.3.23\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_percentage_error\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Download stopwords and punkt tokenizer from NLTK\nnltk.download('stopwords')\nnltk.download('punkt')\n", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "[nltk_data] Downloading package stopwords to /home/wsuser/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /home/wsuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n", "name": "stderr"}, {"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "True"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='gQHGPKfSS9ra4Tie0SYCom5XBBjih7GficmCX-V2opao',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.eu-de.cloud-object-storage.appdomain.cloud')\n\nbucket = 'amazonmlchallenge-donotdelete-pr-oaqyh2hr4halsq'\nobject_key = 'train.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ntrain_df = pd.read_csv(body)\ntrain_df.head()\n", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "   PRODUCT_ID                                              TITLE  \\\n0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n4      283658  The United Empire Loyalists: A Chronicle of th...   \n\n                                       BULLET_POINTS  \\\n0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n3  [Made By 95%cotton and 5% Lycra which gives yo...   \n4                                                NaN   \n\n                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n0                                                NaN             1650   \n1                                                NaN             2755   \n2  Specifications: Color: Red, Material: Aluminiu...             7537   \n3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n4                                                NaN             6112   \n\n   PRODUCT_LENGTH  \n0     2125.980000  \n1      393.700000  \n2      748.031495  \n3      787.401574  \n4      598.424000  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_ID</th>\n      <th>TITLE</th>\n      <th>BULLET_POINTS</th>\n      <th>DESCRIPTION</th>\n      <th>PRODUCT_TYPE_ID</th>\n      <th>PRODUCT_LENGTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1925202</td>\n      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n      <td>NaN</td>\n      <td>1650</td>\n      <td>2125.980000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2673191</td>\n      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n      <td>NaN</td>\n      <td>2755</td>\n      <td>393.700000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2765088</td>\n      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n      <td>7537</td>\n      <td>748.031495</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1594019</td>\n      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n      <td>2996</td>\n      <td>787.401574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>283658</td>\n      <td>The United Empire Loyalists: A Chronicle of th...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6112</td>\n      <td>598.424000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='gQHGPKfSS9ra4Tie0SYCom5XBBjih7GficmCX-V2opao',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.eu-de.cloud-object-storage.appdomain.cloud')\n\nbucket = 'amazonmlchallenge-donotdelete-pr-oaqyh2hr4halsq'\nobject_key = 'test.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ntest_df = pd.read_csv(body)\ntest_df.head()", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "   PRODUCT_ID                                              TITLE  \\\n0      604373  Manuel d'H\u00e9liogravure Et de Photogravure En Re...   \n1     1729783  DCGARING Microfiber Throw Blanket Warm Fuzzy P...   \n2     1871949  I-Match Auto Parts Front License Plate Bracket...   \n3     1107571  PinMart Gold Plated Excellence in Service 1 Ye...   \n4      624253  Visual Mathematics, Illustrated by the TI-92 a...   \n\n                                       BULLET_POINTS  \\\n0                                                NaN   \n1  [QUALITY GUARANTEED: Luxury cozy plush polyest...   \n2  [Front License Plate Bracket Made Of Plastic,D...   \n3  [Available as a single item or bulk packed. Se...   \n4                                                NaN   \n\n                                         DESCRIPTION  PRODUCT_TYPE_ID  \n0                                                NaN             6142  \n1  <b>DCGARING Throw Blanket</b><br><br> <b>Size ...             1622  \n2  Replacement for The Following Vehicles:2020 LE...             7540  \n3  Our Excellence in Service Lapel Pins feature a...            12442  \n4                                                NaN             6318  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_ID</th>\n      <th>TITLE</th>\n      <th>BULLET_POINTS</th>\n      <th>DESCRIPTION</th>\n      <th>PRODUCT_TYPE_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>604373</td>\n      <td>Manuel d'H\u00e9liogravure Et de Photogravure En Re...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6142</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1729783</td>\n      <td>DCGARING Microfiber Throw Blanket Warm Fuzzy P...</td>\n      <td>[QUALITY GUARANTEED: Luxury cozy plush polyest...</td>\n      <td>&lt;b&gt;DCGARING Throw Blanket&lt;/b&gt;&lt;br&gt;&lt;br&gt; &lt;b&gt;Size ...</td>\n      <td>1622</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1871949</td>\n      <td>I-Match Auto Parts Front License Plate Bracket...</td>\n      <td>[Front License Plate Bracket Made Of Plastic,D...</td>\n      <td>Replacement for The Following Vehicles:2020 LE...</td>\n      <td>7540</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1107571</td>\n      <td>PinMart Gold Plated Excellence in Service 1 Ye...</td>\n      <td>[Available as a single item or bulk packed. Se...</td>\n      <td>Our Excellence in Service Lapel Pins feature a...</td>\n      <td>12442</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>624253</td>\n      <td>Visual Mathematics, Illustrated by the TI-92 a...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6318</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Define a function to preprocess the text data\ndef preprocess_text(text):\n    # Convert text to lowercase\n    text = text.lower()\n    # Tokenize the text\n    tokens = word_tokenize(text)\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    filtered_tokens = [token for token in tokens if token not in stop_words]\n    # Stem the tokens\n    stemmer = PorterStemmer()\n    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n    # Join the stemmed tokens back into a string\n    preprocessed_text = ' '.join(stemmed_tokens)\n    return preprocessed_text", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def preprocess_text(text):\n    if isinstance(text, float) and np.isnan(text):\n        return ''\n    # Tokenize the text\n    words = word_tokenize(text.lower())\n    \n    # Remove stopwords\n    words = [word for word in words if word not in stop_words]\n    \n    # Join the remaining words\n    return ' '.join(words)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\ndef preprocess_text(text):\n    \"\"\"\n    Removes leading and trailing whitespace from the given text string.\n\n    Parameters:\n    text (str or float): The text string to preprocess.\n\n    Returns:\n    str or float: The preprocessed text string with leading and trailing whitespace removed, or the original input if it is not a string.\n    \"\"\"\n    if isinstance(text, str):\n        return text.strip()\n    else:\n        return text\n\n\n# Combine the text columns and preprocess the text\ntrain_df['TEXT'] = train_df['TITLE'] + ' ' + train_df['DESCRIPTION'] + ' ' + train_df['BULLET_POINTS']\ntrain_df['TEXT'] = train_df['TEXT'].apply(preprocess_text)\ntest_df['TEXT'] = test_df['TITLE'] + ' ' + test_df['DESCRIPTION'] + ' ' + test_df['BULLET_POINTS']\ntest_df['TEXT'] = test_df['TEXT'].apply(preprocess_text)", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(train_df['TEXT'], train_df['PRODUCT_LENGTH'], test_size=0.2, random_state=42)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Replace missing values with empty strings\nX_train = X_train.fillna('')\nX_val = X_val.fillna('')\n\n# Extract features from the text columns using TfidfVectorizer\ntfidf = TfidfVectorizer(max_features=5000)\nX_train_tfidf = tfidf.fit_transform(X_train)\nX_val_tfidf = tfidf.transform(X_val)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Train a linear regression model\nreg = LinearRegression()\nreg.fit(X_train_tfidf, y_train)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Make predictions on the validation set\ny_pred = reg.predict(X_val_tfidf)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import metrics\n# Evaluate the model using mean absolute percentage error\nscore = max(0,100*(1-metrics.mean_absolute_percentage_error(y_val, y_pred)))\nprint(\"Model score: \", score)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "test_df['TEXT'] = test_df['TEXT'].fillna('')\n# Make predictions on the test set\ntest_df_tfidf = tfidf.transform(test_df['TEXT'])\ntest_df['PRODUCT_LENGTH'] = reg.predict(test_df_tfidf)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from project_lib import Project\nimport pandas as pd\n\n# Set up the project object\nproject = Project(None, \"e149480b-6547-4478-8897-98a96ce36d15\", \"p-eee9223a6d49755e4097f9449708b24d17c6b86c\")\n\n# Create a Pandas dataframe with your data\nsubmission_df = test_df[['PRODUCT_ID', 'PRODUCT_LENGTH']]\n\n# Save the dataframe to a CSV file in IBM Watson Studio\nproject.save_data(\"submission.csv\", submission_df.to_csv(index=False), overwrite=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}
